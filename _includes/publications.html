<!-- !Autonomous UAV -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Autonomous UAV-based Target Search, Tracking and Following using Reinforcement Learning and 
            YoloFLOW</b>
    </font>
    <br>
    <i>IEEE Robotics and Automation Letters-2020</i>
    <br>
    Ajmera, Y., <b>Singh, S.</b> 
</p>
<table class="publications">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <img src="assets/img/UAV_view.png" width="250" height="200" class="zoom" alt="UAV View">
            </div>
            <div class="project_cell">
                [<a href="assets/videos/SSRR_paper_recording.mp4" target="_blank">
                    Video
                </a>]
                [<a href="https://ieeexplore.ieee.org/abstract/document/9292630" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    We developed a UAV-based system for search and rescue missions, integrating reinforcement learning for autonomous navigation and YOLO with Optical Flow for real-time target tracking. This approach enables the UAV to find and follow victims in cluttered environments, ensuring their locations are continually updated for swift evacuation. Extensive simulations demonstrate the system's effectiveness in urban search and rescue scenarios.
                </p>
            </div>
        </td></tr>
    </tbody>
</table>

<!-- !Twilight SLAM: Navigating Low-Light Environments -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Twilight SLAM: Navigating Low-Light Environments</b>
    </font>
    <br>
    <i>arXiv:2304.11310-2023</i>
    <br>
    <b>Singh, S.</b>, Mazotti, B., Rajani, DM., Mayilvahanan, S., Li, G., Ghaffari M.
</p>
<table class="publications">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <img src="assets/img/twilight_slam.png" width="250" height="200" class="zoom" alt="Twilight-SLAM">
            </div>
            <div class="project_cell">
                [<a href="https://www.youtube.com/watch?v=qe87hcqmZm0" target="_blank">
                    Video
                </a>]
                [<a href="https://arxiv.org/pdf/2304.11310" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    This work presents a detailed examination of lowlight visual Simultaneous Localization and Mapping (SLAM) pipelines, focusing on the integration of state-of-the-art (SOTA) low-light image enhancement algorithms with standard and contemporary SLAM frameworks. The primary objective of our work is to address a pivotal question: Does illuminating visual input significantly improve localization accuracy in both semidark and dark environments?
                </p>
            </div>
        </td></tr>
    </tbody>
</table>

<!-- !OriCon3D: Monocular 3D Object Detection -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>OriCon3D: Effective 3D Object Detection using Orientation and Confidence</b>
    </font>
    <br>
    <i>arXiv:2304.11310-2023</i>
    <br>
    Rajani, DM., <b>Singh, S.</b>, Swayampakula, RK.
</p>
<table class="publications">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <img src="assets/img/oricon_paper.png" width="250" height="200" class="zoom" alt="OriCon3D">
            </div>
            <div class="project_cell">
                [<a href="https://arxiv.org/pdf/2304.14484" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    In this work, we propose a simple yet very effective methodology for the detection of 3D objects and precise estimation of their spatial positions from a single image. Unlike conventional frameworks that rely solely on center-point and dimension predictions, our research leverages a deep convolutional neural network-based 3D object weighted orientation regression paradigm. These estimates are then seamlessly integrated with geometric constraints obtained from a 2D bounding box, resulting in derivation of a comprehensive 3D bounding box.
                </p>
            </div>
        </td></tr>
    </tbody>
</table>

<!-- !SCORBOT ER-4U -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Energy Efficiency Enhancement of SCORBOT ER-4U Manipulator Using Topology Optimization Method</b>
    </font>
    <br>
    <i>Mechanics Based Design of Structures and Machines-2021</i>
    <br>
    Srinivas, L., Aadityaa, J., <b>Singh, S.</b>, Javed, A 
</p>
<table class="publications">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <img src="assets/img/scorbot-er4u.png" width="250" height="200" class="zoom" alt="Scorbot ER-4U">
            </div>
            <div class="project_cell">
                [<a href="https://www.tandfonline.com/doi/abs/10.1080/15397734.2021.1972308" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    In this work, topology optimization of the upper and forearm of a 6-DoF Scorbot manipulator was performed considering dynamic loading conditions. A motion study in SolidWorks led to a 30% reduction in peak stress and a 15% decrease in deflection. Additionally, MATLABâ€™s Lagrange-Euler model demonstrated a 40% increase in energy efficiency.
                </p>
            </div>
        </td></tr>
    </tbody>
</table>

<!-- !Experimental evaluation -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Experimental evaluation of topologically optimized Manipulator-link using PLC and HMI based control system</b>
    </font>
    <br>
    <i> International Mechanical Engineering Congress-2019</i>
    <br>
    Srinivas, L., <b>Singh, S.</b>, Javed, A 
</p>
<table class="publications">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <img src="assets/img/trio_robot.png" width="250" height="200" class="zoom" alt="Trio robot">
            </div>
            <div class="project_cell">
                [<a href="https://www.sciencedirect.com/science/article/pii/S221478532035882X" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    In this work, a universal test setup for a 1-DoF manipulator link was developed to validate Von Mises stress values under static loading conditions. Strain data captured with LabVIEW and DAQ showed stress measurements within 1.27% of MATLAB simulations. Dynamic stress analysis of a 3-DoF TRR manipulator in MSC Adams achieved a mean error under 2% compared to simulations.
                </p>
            </div>
        </td></tr>
    </tbody>
</table>